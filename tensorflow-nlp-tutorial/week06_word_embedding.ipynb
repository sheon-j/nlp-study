{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBKa8QLJZaDlx0zt/Coj5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheon-j/nlp-study/blob/main/tensorflow-nlp-tutorial/week06_word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Study: Week 6 - Word Embedding\n",
        "\n",
        "[딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155) 스터디\n",
        "\n",
        "---\n",
        "\n",
        "**Contents**\n",
        "8. 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)\n",
        "9. 엘모(Embeddings from Language Model, ELMo)\n",
        "10. 임베딩 벡터의 시각화(Embedding Visualization)"
      ],
      "metadata": {
        "id": "WAnpv8gvIOrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)"
      ],
      "metadata": {
        "id": "hCqB384r6JbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1. 케라스 임베딩 층(Keras Embedding layer)"
      ],
      "metadata": {
        "id": "gzjaPIIs6YoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2. 사전 훈련된 워드 임베딩(Pre-Trained Word Embedding) 사용하기"
      ],
      "metadata": {
        "id": "ZgIqcvi-6ZN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. 엘모(Embeddings from Language Model, ELMo)"
      ],
      "metadata": {
        "id": "IlGD7Fwk6ZCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1. ELMo(Embeddings from Language Model)"
      ],
      "metadata": {
        "id": "fEMvX4T66ZLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2. biLM(Bidirectional Language Model)의 사전 훈련"
      ],
      "metadata": {
        "id": "OGa0KARl6ZJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3. biLM의 활용"
      ],
      "metadata": {
        "id": "1gDltf2G6ZHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.4. ELMo 표현을 사용해서 스팸 메일 분류하기"
      ],
      "metadata": {
        "id": "hlKYrySo6ZEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. 임베딩 벡터의 시각화(Embedding Visualization)"
      ],
      "metadata": {
        "id": "4wuqZHV06Y_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1. 워드 임베딩 모델로부터 2개의 tsv 파일 생성하기"
      ],
      "metadata": {
        "id": "E_DQ2GGI65tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2. 임베딩 프로젝터를 사용하여 시각화하기"
      ],
      "metadata": {
        "id": "2vKlVRRa6-WX"
      }
    }
  ]
}