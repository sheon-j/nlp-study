{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbWwGsrVY/lcFjBnm6qg2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheon-j/nlp-study/blob/main/tensorflow-nlp-tutorial/week04_a_summary_of_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Study: Week 4 - A Summary of Deep Learning\n",
        "\n",
        "[딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155) 스터디\n",
        "\n",
        "---\n",
        "\n",
        "**Contents**\n",
        "10. 다층 퍼셉트론(MultiLayer Perceptron, MLP)으로 텍스트 분류하기\n",
        "11. 피드 포워드 신경망 언어 모델(Neural Network Language Model, NNLM)"
      ],
      "metadata": {
        "id": "WAnpv8gvIOrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. 다층 퍼셉트론(MultiLayer Perceptron, MLP)으로 텍스트 분류하기\n",
        "* 다층 퍼셉트론(Multilayer Perceptron, MLP)으로 텍스트 분류를 수행"
      ],
      "metadata": {
        "id": "8o-ks3KdImre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1. 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
        "![img](https://wikidocs.net/images/page/24987/mlp_final.PNG)\n",
        "* 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
        "  * 단층 퍼셉트론에서 은닉층이 1개 이상 추가 된 신경망\n",
        "  * 피드 포워드 신경망의 기본적인 형태\n",
        "* 피드 포워드 신경망(Feed Forward Neural Network, FFNN)\n",
        "  * 입력층에서 출력층으로 오직 한 방향으로 연산하는 신경망 (<-> 순환신경망)\n",
        "  * 지금까지 배운 개념을 활용해 자연어 처리에 목적"
      ],
      "metadata": {
        "id": "Ee8EOz8UIqdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2. 케라스의 texts_to_matrix() 이해하기\n",
        "\n",
        "* 입력된 텍스트 데이터로부터 행렬(matrix)를 만드는 도구\n",
        "* `texts_to_matrx()`의 네 가지 모드\n",
        "  1. `binary`\n",
        "  2. `count`\n",
        "  3. `freq`\n",
        "  4. `tfidf`"
      ],
      "metadata": {
        "id": "F6EZDXpeI0B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화와 정수 인코딩\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkO9hZbK9sg",
        "outputId": "96aa52ee-0085-42f6-8da4-48e42d53551d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) count\n",
        "* 문서 단어 행렬(Document-Term Matrix, DTM)을 생성\n",
        "  * BoW 기반. 순서 없음\n",
        "* word_index의 결과 matrix\n",
        "\n",
        "| 문장/토큰               | 바나나 | 먹고 | 싶은 | 사과 | 길고 | 노란 | 저는 | 과일이 | 좋아요 |\n",
        "| ----------------------- | ------ | ---- | ---- | ---- | ---- | ---- | ---- | ------ | ------ |\n",
        "| 먹고 싶은 사과          | 0      | 1    | 1    | 1    | 0    | 0    | 0    | 0      | 0      |\n",
        "| 먹고 싶은 바나나        | 1      | 1    | 1    | 0    | 0    | 0    | 0    | 0      | 0      |\n",
        "| 길고 노란 바나나 바나나 | 2      | 0    | 0    | 0    | 1    | 1    | 0    | 0      | 0      |\n",
        "| 저는 과일이 좋아요      | 0      | 0    | 0    | 0    | 0    | 0    | 1    | 1      | 1      |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8XKsD4DEMf1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# texts_to_matrix의 입력으로 texts를 넣고, 모드는 'count'\n",
        "print(tokenizer.texts_to_matrix(texts, mode = 'count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCSSFKfTMlS9",
        "outputId": "2578533f-225e-4126-bd00-9bc1583b4fed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) binary\n",
        "* 존재 유무로만 행렬을 표현 (True / False)"
      ],
      "metadata": {
        "id": "Z5myzAeqOjtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.texts_to_matrix(texts, mode = 'binary'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHy3GzJ9OnGx",
        "outputId": "37146b81-e945-48ed-ee33-d89656b09ddb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (3) tfidf\n",
        "* TF-IDF (Term Frequency-Inverse Document Frequency, 단어 빈도-역 문서 빈도)\n",
        "  * 빈도수 기반 단어 표현 + 중요도(가중치)\n",
        "  * DTM 내에 있는 각 단어에 대한 중요도를 계산\n",
        "  * TF 구현식이 기존 방식과 조금 다름"
      ],
      "metadata": {
        "id": "cQPd-QB4O6qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 둘째 자리까지 반올림하여 출력\n",
        "print(tokenizer.texts_to_matrix(texts, mode = 'tfidf').round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OKrqhsGOnLK",
        "outputId": "fe30a968-83f4-4a94-a9da-29ac507c9063"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.85 0.85 1.1  0.   0.   0.   0.   0.  ]\n",
            " [0.   0.85 0.85 0.85 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   1.43 0.   0.   0.   1.1  1.1  0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   1.1  1.1  1.1 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (4) freq\n",
        "* $\\frac{단어 등장 횟수}{모든 단어의 개수}$\n",
        "* 예시 '길고 노란 바나나 바나나'\n",
        "  * 바나나: 2/4\n",
        "  * 길고, 노란: 1/4"
      ],
      "metadata": {
        "id": "IjWUx_syQS-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 둘째 자리까지 반올림하여 출력\n",
        "print(tokenizer.texts_to_matrix(texts, mode = 'freq').round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb89TFRGOnI-",
        "outputId": "7616fe13-1107-4130-e0ce-c09e4e0645fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.33 0.33 0.33 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.33 0.33 0.33 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.5  0.   0.   0.   0.25 0.25 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.33 0.33 0.33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.3. 20개 뉴스 그룹(Twenty Newsgroups) 데이터에 대한 이해\n",
        "* 사이킷런의 내장 데이터셋\n",
        "* 20개의 다른 주제를 가진 18,846개의 뉴스 그룹 이메일 데이터\n",
        "* 과제: 테스트 데이터에서 이메일 본문을 보고 20개의 주제 중 어떤 주제인지를 맞추는 것"
      ],
      "metadata": {
        "id": "D0frJfMII4-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) 데이터 확인"
      ],
      "metadata": {
        "id": "QALMZk9lX3MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 'train'을 기재하면 훈련 데이터만 리턴 (all/train/test)\n",
        "newsdata = fetch_20newsgroups(subset='train')"
      ],
      "metadata": {
        "id": "KtqdeWlCR7pv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터 속성:', *newsdata.keys()) # data, target(target_name)\n",
        "print('훈련용 샘플의 개수:', len(newsdata.data))\n",
        "print('총 주제의 개수: ', len(newsdata.target_names))\n",
        "newsdata.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ap6biOZSRKU",
        "outputId": "05ff0814-36af-4756-cf8e-dd00d394dc32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 속성: data filenames target_names target DESCR\n",
            "훈련용 샘플의 개수: 11314\n",
            "총 주제의 개수:  20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(newsdata.data[8])\n",
        "print(newsdata.target[8], newsdata.target_names[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TEUNAASTSZr",
        "outputId": "bbbf00d7-fe2c-483a-96bc-8ea29fd0ac49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: holmes7000@iscsvax.uni.edu\n",
            "Subject: WIn 3.0 ICON HELP PLEASE!\n",
            "Organization: University of Northern Iowa\n",
            "Lines: 10\n",
            "\n",
            "I have win 3.0 and downloaded several icons and BMP's but I can't figure out\n",
            "how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\n",
            "\n",
            "\n",
            "Thanx,\n",
            "\n",
            "-Brando\n",
            "\n",
            "PS Please E-mail me\n",
            "\n",
            "\n",
            "2 comp.os.ms-windows.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) 데이터 EDA"
      ],
      "metadata": {
        "id": "xCcfBuNFS4Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(newsdata.data, columns = ['email'])\n",
        "data['target'] = pd.Series(newsdata.target)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zPYA-pMhV9oe",
        "outputId": "70764955-23d0-4ce6-9388-73aef63872c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ba433ca-9a2a-4961-81ff-849116da3af9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ba433ca-9a2a-4961-81ff-849116da3af9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ba433ca-9a2a-4961-81ff-849116da3af9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ba433ca-9a2a-4961-81ff-849116da3af9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               email  target\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# non-null\n",
        "print(data.info())\n",
        "# unique value\n",
        "print('x:', data['email'].nunique())\n",
        "print('y:', data['target'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5v5G6KvWHLP",
        "outputId": "27075122-4346-4c2e-e1f8-89f463b3d87e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11314 entries, 0 to 11313\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   email   11314 non-null  object\n",
            " 1   target  11314 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 176.9+ KB\n",
            "None\n",
            "x: 11314\n",
            "y: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 타겟 값 분포\n",
        "data['target'].value_counts().plot(kind='bar');\n",
        "print(data.groupby('target').count().T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "MxZAGpiRW1tq",
        "outputId": "67af1db6-bf12-420f-dfe3-a371c9f63903"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target   0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
            "email   480  584  591  590  578  593  585  594  598  597  600  595  591  594   \n",
            "\n",
            "target   14   15   16   17   18   19  \n",
            "email   593  599  546  564  465  377  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (3) 데이터 Split"
      ],
      "metadata": {
        "id": "mWZOYgseX9XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "train_email = data['email']         # train feature\n",
        "train_label = data['target']        # train target\n",
        "test_email = newsdata_test.data     # test feature\n",
        "test_label = newsdata_test.target   # test target"
      ],
      "metadata": {
        "id": "44TrF--eYDSI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # max len\n",
        "num_classes = 20\n",
        "\n",
        "# 전처리 함수\n",
        "def prepare_data(train_data, test_data, mode):\n",
        "    tokenizer = Tokenizer(num_words = vocab_size) # vocab_size 만큼의 단어만 사용\n",
        "    tokenizer.fit_on_texts(train_data)            # 기준 fit\n",
        "    X_train = tokenizer.texts_to_matrix(train_data, mode=mode)  # data × vocab_size\n",
        "    X_test = tokenizer.texts_to_matrix(test_data, mode=mode)    # data × vocab_size\n",
        "    return X_train, X_test, tokenizer.index_word"
      ],
      "metadata": {
        "id": "NbPL7jxnYXzj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature binary 모드로 변환\n",
        "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary')\n",
        "# target 원-핫 인코딩\n",
        "y_train = to_categorical(train_label, num_classes)\n",
        "y_test = to_categorical(test_label, num_classes)"
      ],
      "metadata": {
        "id": "3fihZkIqZbgb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train feature:', X_train.shape)\n",
        "print('train target:', y_train.shape)\n",
        "print('test feature:', X_test.shape)\n",
        "print('test target:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtoVFf0gazZr",
        "outputId": "32646aa9-8c24-4bb1-e87c-dc616c0fc7aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train feature: (11314, 10000)\n",
            "train target: (11314, 20)\n",
            "test feature: (7532, 10000)\n",
            "test target: (7532, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('빈도수 상위 5:',[index_to_word[i] for i in range(1, 6)])\n",
        "print('빈도수 하위 5:',[index_to_word[i] for i in range(vocab_size-5, vocab_size)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ipuznSmccsB",
        "outputId": "6dd334f4-1e9f-40c1-f37e-33e2608cc9e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 5: ['the', 'to', 'of', 'a', \"'ax\"]\n",
            "빈도수 하위 5: ['atterlep', 'fairing', 'informative', 'nyu', 'mic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.4. 다층 퍼셉트론(Multilayer Perceptron, MLP)을 사용하여 텍스트 분류하기\n",
        "\n",
        "* 입력값을 바꿔가면서 모델을 여러번 호출 -> 함수 정의"
      ],
      "metadata": {
        "id": "GGDDiEtDI43e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_shape=(vocab_size,), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, batch_size=128, epochs=5,\n",
        "              verbose=0, validation_split=0.1)\n",
        "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
        "    return score[1]"
      ],
      "metadata": {
        "id": "kWSFTsitU7wS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://wikidocs.net/images/page/49071/multilayerperceptron.PNG)\n",
        "* 총 4개의 층\n",
        "  * vocab_size 크기(10000)의 입력층\n",
        "  * 256개 뉴런의 은닉층1 (relu)\n",
        "  * 128개 뉴런의 은닉층2 (relu)\n",
        "  * num_classes 크기(20)의 출력층 \n",
        "* 과적합 방지: 두 번의 드롭 아웃\n",
        "* 다중 분류\n",
        "  * 소프트 맥스 함수\n",
        "  * 카테고리컬 크로스 엔트로피 (손실 함수)\n",
        "* 은닉층이 2개이므로 깊은 신경망(Deep Neural Network, DNN)\n"
      ],
      "metadata": {
        "id": "7TbyT01aWSyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# texts_to_matrix의 4가지 모드\n",
        "modes = ['binary', 'count', 'tfidf', 'freq']\n",
        "\n",
        "for mode in modes:\n",
        "    # 모드에 따라서 데이터를 전처리\n",
        "    X_train, X_test, _ = prepare_data(train_email, test_email, mode)\n",
        "    # 모델을 훈련하고 평가\n",
        "    score = fit_and_evaluate(X_train, y_train, X_test, y_test)\n",
        "    print(f'{mode} 모드의 테스트 정확도: {round(score, 3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBtRPSdJatQn",
        "outputId": "ef5dee63-aa77-4fef-a585-0577c07f6073"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary 모드의 테스트 정확도: 0.827\n",
            "count 모드의 테스트 정확도: 0.823\n",
            "tfidf 모드의 테스트 정확도: 0.832\n",
            "freq 모드의 테스트 정확도: 0.702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 82% ~ 83%의 비슷한 정확도\n",
        "* freq 모드에서만 정확도가 70%\n",
        "* freq 모드는 이번 문제를 풀기위한 적절한 전처리 방법이 아님\n",
        "---"
      ],
      "metadata": {
        "id": "jTbfLvaIg6_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. 피드 포워드 신경망 언어 모델(Neural Network Language Model, NNLM)\n",
        "\n",
        "* 배경 지식\n",
        "  * 과거 기계가 자연어를 학습하게 하는 방법으로 통계적인 접근을 사용\n",
        "    * 통계적 언어 모델(Statistical Language Model, SLM)\n",
        "  * 최근에는 인공 신경망을 사용하는 방법이 자연어 처리에서 더 좋은 성능\n",
        "    * 자연어 생성(Natural Language Generation, NLG)\n",
        "  * 통계적 언어 모델에서 다양한 구조의 인공 신경망을 사용한 언어 모델들로 대체\n",
        "\n",
        "* 피드 포워드 신경망 언어 모델(Feed Forward Neural Network Language Model)\n",
        "  * 신경망 언어 모델의 시초 NNLM\n",
        "  * RNNLM, BiLM 등 보다 발전된 신경망 언어 모델들을 배우기 전 시초를 훑자"
      ],
      "metadata": {
        "id": "ST4fa81fI4pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.1. 기존 N-gram 언어 모델의 한계\n",
        "\n",
        "* 언어 모델은 문장에 확률을 할당하는 모델\n",
        "* 주어진 문맥으로부터 아직 모르는 단어를 예측하는 것을 언어 모델링이라 함\n",
        "* N-gram 예시\n",
        "  ```python \n",
        "  # 다음 단어 예측하기\n",
        "  An adorable little boy is spreading _____\n",
        "  ```\n",
        "\n",
        "  * 언어 모델링에 바로 앞 n-1개의 단어를 참고\n",
        "  * 4-gram 언어 모델이라고 가정. 모델은 바로 앞 3개의 단어만 참고\n",
        "  * 빈 칸 예측에 사용되는 단어는 boy, is, spreading\n",
        "\n",
        " \n",
        "$$P(w|boy, is, spreading)=\\frac{count(boy, is, spreading, w)}{count(boy, is, spreading)}$$\n",
        "\n",
        "  * boy is spreading가 1000번, boy is spreading insults가 500번, boy is spreading smiles가 200번 등장\n",
        "    * P(insults | boy is spreading) = 0.500\n",
        "    * P(smiles | boy is spreading) = 0.200\n",
        "\n",
        "* 희소 문제(sparsity problem)\n",
        "  * n-gram 언어 모델은 충분한 데이터를 관측하지 못하면 언어를 정확히 모델링하지 못함\n",
        "  * boy is spreading smile라는 단어 시퀀스가 존재하지 않으면 n-gram 언어 모델에서 해당 단어 시퀀스의 확률은 0\n",
        "  * 언어 모델이 판단하기에 boy is spreading 다음에는 smiles이란 단어가 나올 수 없다는 의미\n",
        "  * 해당 단어 시퀀스는 현실에서 존재 가능한 시퀀스이므로 적절한 모델링이 아님"
      ],
      "metadata": {
        "id": "KSGi2cI0JMWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.2. 단어의 의미적 유사성\n",
        "\n",
        "* **희소 문제**는 기계가 단어의 의미적 유사성을 알수 있다면 해결할 수 있는 문제\n",
        "  * `...발표 자료를 살펴보다...`\n",
        "  * p(살펴보다|발표 자료를) = 0.n\n",
        "  * p(훑어보다|발표 자료를) = ~0~ -> 0.m\n",
        "* 언어 모델 또한 단어의 의미적 유사성을 학습할 수 있도록 설계 목표\n",
        "* 코퍼스에 없는 단어에 대한 예측이라도 **유사 단어**의 시퀀스를 참고하여 예측 정확도 보정\n",
        "  * **NNLM 신경망**\n",
        "  * 워드 임베딩 (벡터간 유사도)"
      ],
      "metadata": {
        "id": "17AU8xN_JPhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.3. 피드 포워드 신경망 언어 모델(NNLM)"
      ],
      "metadata": {
        "id": "9EqLohJ3JRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) 예문 : \"what will the fat cat sit on\"\n",
        "  * 언어 모델은 주어진 단어 시퀀스로부터 다음 단어를 예측\n",
        "  * what will the fat cat __ => sit 을 예측\n"
      ],
      "metadata": {
        "id": "QZ4nbigIGfJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) 기계가 단어를 인식할 수 있도록 모든 단어 수치화 (인코딩)\n",
        "  ```python\n",
        "  # 원 핫 인코딩\n",
        "  what = [1, 0, 0, 0, 0, 0, 0]\n",
        "  will = [0, 1, 0, 0, 0, 0, 0]\n",
        "  the = [0, 0, 1, 0, 0, 0, 0]\n",
        "  fat = [0, 0, 0, 1, 0, 0, 0]\n",
        "  cat = [0, 0, 0, 0, 1, 0, 0]\n",
        "  sit = [0, 0, 0, 0, 0, 1, 0]\n",
        "  on = [0, 0, 0, 0, 0, 0, 1]\n",
        "  ```\n",
        "  * NNLM의 입력이면서 예측을 위한 레이블\n",
        "  * what will the fat cat 입력 => sit 예측"
      ],
      "metadata": {
        "id": "Qgn2tjzxrMp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (3) NNLM 훈련\n",
        "  * NNLM은 정해진 개수(**window**)의 단어만을 참고하여 예측 (n-gram과 동일)\n",
        "  \n",
        "  ![img](https://wikidocs.net/images/page/45609/nnlm1.PNG)\n",
        "  * 4개의 단어 입력 => 다중 클래스 예측(오차 발생) => 학습(손실 함수에 따라 parameter 조정)\n",
        "  * Input Layer (입력층)\n",
        "    * 윈도우 4, 원 핫 인코딩 입력\n",
        "  * Projection Layer (투사층)\n",
        "  \n",
        "  ![img](https://wikidocs.net/images/page/45609/nnlm2_renew.PNG)\n",
        "    * fat을 의미하는 원-핫 벡터 X fat\n",
        "    * W (가중치)\n",
        "      * 단어 집합의 크기 V(7), 투사층의 크기 M(5)\n",
        "      * 투사층: 가중치 행렬과의 곱셈은 이루어지지만 활성화 함수가 존재하지 않음\n",
        "      * 룩업 테이블\u001f: 원-핫 벡터와 가중치 W 행렬의 곱은 사실 W행렬의 i번째 행을 그대로 읽어오는 것과(lookup) 동일\n",
        "    * 룩업 테이블 과정을 거친 임베딩 벡터 e fat\n",
        "      * 임베딩 벡터: 초기 랜덤한 값을 가지지만 학습 과정에서 값이 변경되는 벡터\n",
        "    * 각 단어가 테이블 룩업을 통해 임베딩 벡터로 변경되고, 투사층에서 모든 임베딩 벡터들의 값은 연결(concatenate) \n",
        "    \n",
        "    ![img](https://wikidocs.net/images/page/45609/nnlm3_renew.PNG)\n",
        "  * Hidden Layer (은닉층)\n",
        "    * 은닉층의 입력은 가중치 곱해진 후 편향이 더해져 활성화 함수의 입력\n",
        "  * Output Layer (출력층)\n",
        "\n",
        "    ![img](https://wikidocs.net/images/page/45609/nnlm5_final.PNG)\n",
        "    * 은닉층의 출력은 V의 크기\n",
        "    * 출력층 활성화 함수: 소프트맥스(softmax)\n",
        "      * 벡터의 각 원소는 0과 1사이의 실수값을 가지며 총 합은 1\n",
        "    * 손실 함수: 크로스 엔트로피(cross-entropy) 함수\n",
        "      * 역전파를 통해 가중치 행렬(투사층 + 은닉층)들이 학습"
      ],
      "metadata": {
        "id": "WIMRZV7JrOs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (4) 의의\n",
        "* 만약 충분한 훈련 데이터가 있다면? \n",
        "  * 충분한 양의 훈련 코퍼스를 위와 같은 과정으로 학습\n",
        "  * 수많은 문장에서 유사한 목적으로 사용되는 단어들은 결국 유사한 임베딩 벡터값을 얻음\n",
        "  * 훈련이 끝난 후 다음 단어를 예측 과정에서 훈련 코퍼스에서 없던 단어 시퀀스라 하더라도 다음 단어를 선택이 가능\n",
        "\n",
        "* 단어 간 유사도를 구하는 임베딩 벡터의 아이디어\n",
        "  * Word2Vec, FastText, GloVe 등으로 발전\n",
        "  * 워드 임베딩 챕터에서 자세히 다룸"
      ],
      "metadata": {
        "id": "mB4_i_RXdMwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.4. NNLM의 이점과 한계\n",
        "* NNLM은 기존 n-gram 언어 모델의 한계를 개선"
      ],
      "metadata": {
        "id": "DtiXJT5AJUJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) 이점: 기존 모델에서의 개선점\n",
        "1. NNLM은 단어를 표현하기 위해 **임베딩 벡터**를 사용하므로서 **단어의 유사도**를 계산\n",
        "2. 이를 통해 희소 문제(sparsity problem)를 해결"
      ],
      "metadata": {
        "id": "fIt4MFd9rYsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) 고정된 길이의 입력(Fixed-length input)\n",
        "* n-gram과 같이 정해진 n개의 단어만을 참고 (window)\n",
        "* 한계를 극복할 수 있는 언어 모델 존재\n",
        "  * RNN(Recurrent Neural Network) 언어 모델\n",
        "---"
      ],
      "metadata": {
        "id": "c0wCYqsWrh0y"
      }
    }
  ]
}